{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lrys/nlp2/blob/main/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "42e7oO3O-Gd7"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'get_batch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\123\\Desktop\\NLP2\\Untitled3.ipynb 单元格 2\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/123/Desktop/NLP2/Untitled3.ipynb#W1sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m glove_embedding\u001b[39m.\u001b[39mget_words()  \u001b[39m# 找到所有单词，并标记ID\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/123/Desktop/NLP2/Untitled3.ipynb#W1sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m glove_embedding\u001b[39m.\u001b[39mget_id()  \u001b[39m# 找到每个句子拥有的单词ID\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/123/Desktop/NLP2/Untitled3.ipynb#W1sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m NN_embedding_plot(random_embedding,glove_embedding,alpha,batch_size,iter_times)\n",
            "File \u001b[1;32mc:\\Users\\123\\Desktop\\NLP2\\comparison_plot_batch.py:88\u001b[0m, in \u001b[0;36mNN_embedding_plot\u001b[1;34m(random_embedding, glove_embedding, learning_rate, batch_size, iter_times)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mNN_embedding_plot\u001b[39m(random_embedding, glove_embedding, learning_rate, batch_size, iter_times):\n\u001b[0;32m     87\u001b[0m     \u001b[39m#获得训练集和测试集的batch\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m     train_random \u001b[39m=\u001b[39m get_batch(random_embedding\u001b[39m.\u001b[39mtrain_matrix,\n\u001b[0;32m     89\u001b[0m                              random_embedding\u001b[39m.\u001b[39mtrain_y, batch_size)\n\u001b[0;32m     90\u001b[0m     test_random \u001b[39m=\u001b[39m get_batch(random_embedding\u001b[39m.\u001b[39mtest_matrix,\n\u001b[0;32m     91\u001b[0m                             random_embedding\u001b[39m.\u001b[39mtest_y, batch_size)\n\u001b[0;32m     92\u001b[0m     train_glove \u001b[39m=\u001b[39m get_batch(glove_embedding\u001b[39m.\u001b[39mtrain_matrix,\n\u001b[0;32m     93\u001b[0m                             glove_embedding\u001b[39m.\u001b[39mtrain_y, batch_size)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'get_batch' is not defined"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import random\n",
        "from feature_batch import Random_embedding,Glove_embedding,get_batch\n",
        "import torch\n",
        "from comparison_plot_batch import NN_embedding_plot\n",
        "\n",
        "# 数据读入\n",
        "with open('train.tsv') as f:\n",
        "    tsvreader = csv.reader (f, delimiter ='\\t')\n",
        "    temp = list ( tsvreader )\n",
        "\n",
        "with open('glove.6B.50d.txt','rb') as f:  # for glove embedding\n",
        "    lines=f.readlines()\n",
        "\n",
        "# 用GloVe创建词典\n",
        "trained_dict=dict()\n",
        "n=len(lines)\n",
        "for i in range(n):\n",
        "    line=lines[i].split()\n",
        "    trained_dict[line[0].decode(\"utf-8\").upper()]=[float(line[j]) for j in range(1,51)]\n",
        "\n",
        "# 初始化\n",
        "iter_times=50  # 做50个epoch\n",
        "alpha=0.001\n",
        "\n",
        "# 程序开始\n",
        "data = temp[1:]\n",
        "batch_size=500\n",
        "\n",
        "# 随机初始化\n",
        "random.seed(2021)\n",
        "random_embedding=Random_embedding(data=data)\n",
        "random_embedding.get_words()  # 找到所有单词，并标记ID\n",
        "random_embedding.get_id()  # 找到每个句子拥有的单词ID\n",
        "\n",
        "# 预训练模型初始化\n",
        "random.seed(2021)\n",
        "glove_embedding=Glove_embedding(data=data,trained_dict=trained_dict)\n",
        "glove_embedding.get_words()  # 找到所有单词，并标记ID\n",
        "glove_embedding.get_id()  # 找到每个句子拥有的单词ID\n",
        "\n",
        "NN_embedding_plot(random_embedding,glove_embedding,alpha,batch_size,iter_times)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM7nKXzzWT5jS4yM/qzIkNx",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
